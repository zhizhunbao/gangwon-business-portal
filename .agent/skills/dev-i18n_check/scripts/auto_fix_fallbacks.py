"""
å¢å¼ºç‰ˆ i18n è‡ªåŠ¨ä¿®å¤å·¥å…·
- è‡ªåŠ¨æŸ¥æ‰¾å¹¶åˆå¹¶æ‰€æœ‰ locales ç›®å½•çš„ç¿»è¯‘
- æ‰¹é‡ä¿®å¤ä¸­æ–‡ fallback ä¸ºéŸ©è¯­
- ç”Ÿæˆè¯¦ç»†çš„ä¿®å¤æŠ¥å‘Šå’Œéœ€è¦æ‰‹åŠ¨å¤„ç†çš„åˆ—è¡¨
"""
import re
import sys
import json
from pathlib import Path
from typing import Dict, List, Tuple, Set
from collections import defaultdict


# ============================================================================
# ç¿»è¯‘æ–‡ä»¶åŠ è½½
# ============================================================================

def flatten_dict(d: dict, parent_key: str = '', sep: str = '.') -> Dict[str, str]:
    """å°†åµŒå¥—å­—å…¸å±•å¹³ä¸ºç‚¹å·åˆ†éš”çš„é”®"""
    items = []
    for k, v in d.items():
        new_key = f"{parent_key}{sep}{k}" if parent_key else k
        if isinstance(v, dict):
            items.extend(flatten_dict(v, new_key, sep=sep).items())
        else:
            items.append((new_key, v))
    return dict(items)


def load_all_translations(base_dir: Path) -> Dict[str, str]:
    """åŠ è½½æ‰€æœ‰ locales ç›®å½•çš„ ko.json å¹¶åˆå¹¶"""
    all_translations = {}
    skip_patterns = ['node_modules', '.venv', '_deprecated', 'dist', 'build']

    for locales_dir in base_dir.rglob('locales'):
        if any(skip in str(locales_dir) for skip in skip_patterns):
            continue

        ko_file = locales_dir / 'ko.json'
        if ko_file.exists():
            try:
                data = json.loads(ko_file.read_text(encoding='utf-8'))
                translations = flatten_dict(data)
                all_translations.update(translations)
                print(f"  âœ… åŠ è½½: {ko_file.relative_to(base_dir)} ({len(translations)} ä¸ªé”®)")
            except Exception as e:
                print(f"  âŒ åŠ è½½å¤±è´¥: {ko_file} - {e}")

    return all_translations


def is_korean(text: str) -> bool:
    """æ£€æŸ¥æ–‡æœ¬æ˜¯å¦ä¸»è¦æ˜¯éŸ©è¯­"""
    korean_chars = len(re.findall(r'[\uac00-\ud7af\u1100-\u11ff\u3130-\u318f]', text))
    chinese_chars = len(re.findall(r'[\u4e00-\u9fff]', text))
    return korean_chars > chinese_chars


# ============================================================================
# æ–‡ä»¶æ‰«æå’Œä¿®å¤
# ============================================================================

def find_chinese_fallbacks(file_path: Path) -> List[Dict]:
    """æŸ¥æ‰¾æ–‡ä»¶ä¸­æ‰€æœ‰ä½¿ç”¨ä¸­æ–‡ fallback çš„ t() è°ƒç”¨"""
    try:
        content = file_path.read_text(encoding='utf-8')
    except Exception:
        return []

    # åŒ¹é… t('key', 'ä¸­æ–‡') æˆ– t("key", "ä¸­æ–‡") æ¨¡å¼
    pattern = r"t\((['\"])([^'\"]+)\1\s*,\s*(['\"])([^'\"]*[\u4e00-\u9fff]+[^'\"]*)\3\)"
    issues = []

    for match in re.finditer(pattern, content):
        key = match.group(2)
        fallback = match.group(4)

        line_num = content[:match.start()].count('\n') + 1

        issues.append({
            'key': key,
            'fallback': fallback,
            'line': line_num,
            'match_start': match.start(),
            'match_end': match.end(),
            'full_match': match.group(0)
        })

    return issues


def fix_file(file_path: Path, ko_translations: Dict[str, str], dry_run: bool = True) -> Tuple[int, int, List[Dict]]:
    """
    ä¿®å¤æ–‡ä»¶ä¸­çš„ä¸­æ–‡ fallback

    è¿”å›: (æˆåŠŸä¿®å¤æ•°é‡, æ— æ³•ä¿®å¤æ•°é‡, éœ€è¦æ‰‹åŠ¨å¤„ç†çš„åˆ—è¡¨)
    """
    try:
        content = file_path.read_text(encoding='utf-8')
    except Exception as e:
        print(f"âŒ æ— æ³•è¯»å–æ–‡ä»¶ {file_path}: {e}")
        return 0, 0, []

    issues = find_chinese_fallbacks(file_path)
    if not issues:
        return 0, 0, []

    fixed_count = 0
    unfixable_count = 0
    unfixable_list = []
    new_content = content

    # æŒ‰ä½ç½®å€’åºå¤„ç†ï¼Œé¿å…ä½ç½®åç§»
    for issue in sorted(issues, key=lambda x: x['match_start'], reverse=True):
        key = issue['key']
        chinese = issue['fallback']

        # æŸ¥æ‰¾éŸ©è¯­ç¿»è¯‘
        if key in ko_translations:
            korean = ko_translations[key]

            # ç¡®ä¿éŸ©è¯­ç¿»è¯‘ä¸æ˜¯ä¸­æ–‡
            if is_korean(korean) and korean != chinese:
                # æ„é€ æ–°çš„ t() è°ƒç”¨
                old_text = issue['full_match']
                new_text = f"t('{key}', '{korean}')"

                # æ›¿æ¢
                new_content = new_content[:issue['match_start']] + new_text + new_content[issue['match_end']:]
                fixed_count += 1
            else:
                # ko.json ä¸­çš„ç¿»è¯‘ä¹Ÿæ˜¯ä¸­æ–‡ï¼Œæ— æ³•ä¿®å¤
                unfixable_count += 1
                unfixable_list.append({
                    'file': str(file_path),
                    'line': issue['line'],
                    'key': key,
                    'chinese': chinese,
                    'korean_value': korean,
                    'reason': 'ko.json ä¸­çš„å€¼ä¹Ÿæ˜¯ä¸­æ–‡æˆ–ç›¸åŒ'
                })
        else:
            # é”®ä¸å­˜åœ¨äº ko.json
            unfixable_count += 1
            unfixable_list.append({
                'file': str(file_path),
                'line': issue['line'],
                'key': key,
                'chinese': chinese,
                'korean_value': None,
                'reason': 'é”®åœ¨ ko.json ä¸­ä¸å­˜åœ¨'
            })

    # å†™å…¥ä¿®æ”¹
    if fixed_count > 0:
        if not dry_run:
            try:
                file_path.write_text(new_content, encoding='utf-8')
            except Exception as e:
                print(f"âŒ å†™å…¥æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
                return 0, unfixable_count, unfixable_list

    return fixed_count, unfixable_count, unfixable_list


# ============================================================================
# æ‰¹é‡å¤„ç†
# ============================================================================

def process_directory(directory: Path, ko_translations: Dict[str, str], dry_run: bool = True):
    """æ‰¹é‡å¤„ç†ç›®å½•ä¸­çš„æ‰€æœ‰ç»„ä»¶æ–‡ä»¶"""
    total_fixed = 0
    total_unfixable = 0
    all_unfixable = []
    fixed_files = []

    extensions = ['.jsx', '.tsx']
    skip_patterns = ['node_modules', 'locales', '.venv', '_deprecated', 'dist', 'build']

    print("\n" + "=" * 80)
    print("å¼€å§‹å¤„ç†æ–‡ä»¶...")
    print("=" * 80 + "\n")

    for ext in extensions:
        for file_path in directory.rglob(f'*{ext}'):
            if any(skip in str(file_path) for skip in skip_patterns):
                continue

            fixed, unfixable, unfixable_list = fix_file(file_path, ko_translations, dry_run)

            if fixed > 0 or unfixable > 0:
                rel_path = file_path.relative_to(directory.parent.parent)
                print(f"ğŸ“„ {rel_path}")
                if fixed > 0:
                    print(f"  âœ… ä¿®å¤: {fixed} å¤„")
                    fixed_files.append((str(rel_path), fixed))
                if unfixable > 0:
                    print(f"  âš ï¸  æ— æ³•ä¿®å¤: {unfixable} å¤„")

                total_fixed += fixed
                total_unfixable += unfixable
                all_unfixable.extend(unfixable_list)

    return total_fixed, total_unfixable, all_unfixable, fixed_files


# ============================================================================
# æŠ¥å‘Šç”Ÿæˆ
# ============================================================================

def generate_unfixable_report(unfixable_list: List[Dict], output_file: Path):
    """ç”Ÿæˆéœ€è¦æ‰‹åŠ¨å¤„ç†çš„é—®é¢˜æŠ¥å‘Š"""
    if not unfixable_list:
        return

    # æŒ‰åŸå› åˆ†ç»„
    by_reason = defaultdict(list)
    for item in unfixable_list:
        by_reason[item['reason']].append(item)

    report = []
    report.append("# éœ€è¦æ‰‹åŠ¨å¤„ç†çš„ i18n é—®é¢˜\n")
    report.append(f"ç”Ÿæˆæ—¶é—´: {Path(__file__).parent.parent}\n")
    report.append(f"\n## æ¦‚è§ˆ\n")
    report.append(f"- æ— æ³•è‡ªåŠ¨ä¿®å¤çš„é—®é¢˜æ€»æ•°: **{len(unfixable_list)}**\n")

    for reason, items in by_reason.items():
        report.append(f"\n### {reason} ({len(items)} å¤„)\n")

        # æŒ‰æ–‡ä»¶åˆ†ç»„
        by_file = defaultdict(list)
        for item in items:
            by_file[item['file']].append(item)

        for file_path, file_items in sorted(by_file.items()):
            report.append(f"\n#### ğŸ“„ `{file_path}`\n")
            for item in file_items:
                report.append(f"\n**è¡Œ {item['line']}**\n")
                report.append(f"- é”®: `{item['key']}`\n")
                report.append(f"- ä¸­æ–‡ fallback: `{item['chinese']}`\n")
                if item['korean_value']:
                    report.append(f"- ko.json å½“å‰å€¼: `{item['korean_value']}`\n")
                report.append(f"\n")

    report.append(f"\n## ä¿®å¤å»ºè®®\n")
    report.append(f"\n### 1. é”®ä¸å­˜åœ¨çš„æƒ…å†µ\n")
    report.append(f"éœ€è¦åœ¨å¯¹åº”çš„ locales/ko.json å’Œ locales/zh.json ä¸­æ·»åŠ ç¿»è¯‘:\n")
    report.append(f"```json\n")
    report.append(f'{{\n')
    report.append(f'  "keyName": "í•œêµ­ì–´ ë²ˆì—­"\n')
    report.append(f'}}\n')
    report.append(f"```\n")

    report.append(f"\n### 2. ko.json ä¸­çš„å€¼ä¹Ÿæ˜¯ä¸­æ–‡\n")
    report.append(f"éœ€è¦ä¿®æ”¹ ko.json ä¸­çš„å€¼ä¸ºæ­£ç¡®çš„éŸ©è¯­ç¿»è¯‘\n")

    output_file.write_text(''.join(report), encoding='utf-8')
    print(f"\nğŸ“ è¯¦ç»†æŠ¥å‘Šå·²ç”Ÿæˆ: {output_file}")


# ============================================================================
# ä¸»å‡½æ•°
# ============================================================================

def main():
    """ä¸»å‡½æ•°"""
    if len(sys.argv) < 2:
        print("ç”¨æ³•: python auto_fix_fallbacks.py <å‰ç«¯ç›®å½•> [--apply]")
        print("ç¤ºä¾‹: python auto_fix_fallbacks.py frontend/src")
        print("      python auto_fix_fallbacks.py frontend/src --apply")
        sys.exit(1)

    directory = Path(sys.argv[1])
    dry_run = '--apply' not in sys.argv

    if dry_run:
        print("ğŸ” é¢„è§ˆæ¨¡å¼ - ä¸ä¼šå®é™…ä¿®æ”¹æ–‡ä»¶")
    else:
        print("âœï¸  åº”ç”¨æ¨¡å¼ - å°†ä¿®æ”¹æ–‡ä»¶")

    print("\n" + "=" * 80)
    print("æ­¥éª¤ 1: åŠ è½½æ‰€æœ‰ç¿»è¯‘æ–‡ä»¶")
    print("=" * 80)

    base_dir = directory.parent
    ko_translations = load_all_translations(base_dir)

    if not ko_translations:
        print("\nâŒ æœªæ‰¾åˆ°ä»»ä½•ç¿»è¯‘æ–‡ä»¶")
        sys.exit(1)

    print(f"\nâœ… å…±åŠ è½½ {len(ko_translations)} ä¸ªéŸ©è¯­ç¿»è¯‘é”®")

    # å¤„ç†æ‰€æœ‰æ–‡ä»¶
    total_fixed, total_unfixable, unfixable_list, fixed_files = process_directory(
        directory, ko_translations, dry_run
    )

    # ç”ŸæˆæŠ¥å‘Š
    print("\n" + "=" * 80)
    print("ä¿®å¤ç»Ÿè®¡")
    print("=" * 80)
    print(f"âœ… æˆåŠŸä¿®å¤: {total_fixed} å¤„")
    print(f"âš ï¸  æ— æ³•è‡ªåŠ¨ä¿®å¤: {total_unfixable} å¤„")
    print(f"ğŸ“ ä¿®æ”¹çš„æ–‡ä»¶æ•°: {len(fixed_files)}")

    if unfixable_list:
        report_file = Path(__file__).parent.parent / 'MANUAL_FIX_NEEDED.md'
        generate_unfixable_report(unfixable_list, report_file)

    if dry_run:
        print("\nâš ï¸  è¿™æ˜¯é¢„è§ˆæ¨¡å¼ã€‚ä½¿ç”¨ --apply å‚æ•°æ¥å®é™…åº”ç”¨æ›´æ”¹ã€‚")
        if total_fixed > 0:
            print(f"   å‘½ä»¤: python auto_fix_fallbacks.py {directory} --apply")
    else:
        print("\nâœ… ä¿®å¤å®Œæˆï¼")
        if total_unfixable > 0:
            print(f"âš ï¸  è¿˜æœ‰ {total_unfixable} å¤„é—®é¢˜éœ€è¦æ‰‹åŠ¨å¤„ç†ï¼Œè¯·æŸ¥çœ‹ MANUAL_FIX_NEEDED.md")


if __name__ == '__main__':
    main()
